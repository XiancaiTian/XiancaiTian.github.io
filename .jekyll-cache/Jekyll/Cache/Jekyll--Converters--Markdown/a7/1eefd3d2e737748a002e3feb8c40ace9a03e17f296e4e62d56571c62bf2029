I"+<p>知乎原文：<a href="https://zhuanlan.zhihu.com/p/57541603">标准化(standardization)和归一化（normalization）</a></p>

<p><strong>注意，我们下面讨论的归一化和标准化针对的都是特征（数据列），而非针对样本（数据行）进行。</strong></p>

<p>归一化（Normalization）和标准化（Standardization）都是为了解决不同特征取值范围相差太大的问题。因为，如果部分特征的取值特别大而远超其他特征的值，那模型训练的结果就会被这少部分的特征所支配，从而错失了其他小值特征所含有用信息。</p>

<!-- more -->

<h2>标准化</h2>
<h3>公式</h3>

<p><strong>z  = (x - u) / s</strong></p>

<p>对每个值x，减去其所在列的平均值u，再除以所在列的标准差s，得到的就是标准化后的值z。每列的标准化独立进行，标准化后的数据每列的均值为0，标准差为1。</p>

<h3>工具</h3>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">sklearn.preprocessing.StandardScaler</a></p>

<p>示例代码：</p>

<pre><code class="language-python">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; data = [[0, 0], [0, 0], [1, 1], [1, 1]]
&gt;&gt;&gt; scaler = StandardScaler()
&gt;&gt;&gt; scaler.fit(data)

&gt;&gt;&gt; print(scaler.mean_)
[0.5 0.5]

&gt;&gt;&gt; print(scaler.transform(data))
[[-1. -1.]
 [-1. -1.]
 [ 1.  1.]
 [ 1.  1.]]

&gt;&gt;&gt; print(scaler.transform([[2, 2]]))
[[3. 3.]]
</code></pre>

<h2>归一化</h2>
<h3>公式</h3>

<p><strong>z  = (x - min) / (max - min)</strong></p>

<p>对每个值x，减去其所在列的最小值min，再除以所在列的极差（最大值与最小值之差），得到的就是归一化后的值z。每列的归一化独立进行，归一化后的数据每列的取值范围为[0, 1]。</p>

<h3>工具</h3>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler">sklearn.preprocessing.MinMaxScaler</a></p>

<p>示例代码：</p>

<pre><code class="language-python">&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler
&gt;&gt;&gt; data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
&gt;&gt;&gt; scaler = MinMaxScaler()
&gt;&gt;&gt; scaler.fit(data)
&gt;&gt;&gt; print(scaler.data_max_)
[ 1. 18.]

&gt;&gt;&gt; print(scaler.transform(data))
[[0.   0.  ]
 [0.25 0.25]
 [0.5  0.5 ]
 [1.   1.  ]]

&gt;&gt;&gt; print(scaler.transform([[2, 2]]))
[[1.5 0. ]]
</code></pre>

<h2>总结</h2>
<p>两种特征缩放的方法都有它们的缺点，如果数据里面含有异常值（Outlier），那归一化会使得绝大部分数据都集中在一个极小的范围值内；而使用标准化转换后的数值可能很大，不像归一化那样有限定的取值范围。</p>
:ET